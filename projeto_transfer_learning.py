# -*- coding: utf-8 -*-
"""projeto-transfer-learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_fe1D8SKQ5ePmKwrN00RpBq4s7rcpau5

Passo 1: Importação de bibliotecas
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import os
import zipfile
from pathlib import Path
import urllib.request
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image

"""Passo 2: Baixar e Extrair dataset"""

# Função para baixar o arquivo zip
def download_dataset(url: str, zip_name: str) -> None:
    print(f"Baixando o arquivo {zip_name}")
    try:
      urllib.request.urlretrieve(url, zip_name)
      print("Download concluído")
    except Exception as e:
      print(f"Erro ao baixar o arquivo: {e}")

# Função descompactar o arquivo zip
def extract_zip_file(url: str, zip_name: str) -> None:
  if not os.path.exists(zip_name): # verifica se o arquivo não existe na pasta raiz
   download_dataset(url, zip_name) # chama a função para baixar o arquivo
  # Tentará extrair o arquivo zip
  try:
    if not os.path.exists('PetImages'): # Verifica se pasta PetImages não existe
      print(f"Descompactando o arquivo {zip_name}")
      with zipfile.ZipFile(zip_name, 'r') as zip_file:
        zip_file.extractall(".") # extrai tudo na pasta raiz
      print("Descompactação concluída")
  except Exception as e:
    print(f"Erro ao extrair o arquivo: {e}")

# remover imagens corrompidas do dataset
def remove_corrupted_images(folder):
    print("Verificando imagens corrompidas...")
    for class_name in os.listdir(folder):
        class_path = os.path.join(folder, class_name)
        if os.path.isdir(class_path):
            for img_name in os.listdir(class_path):
                img_path = os.path.join(class_path, img_name)
                try:
                    img = Image.open(img_path)
                    img.verify() # verificando a imagem
                except (IOError, SyntaxError):
                    print(f"Removendo imagem corrompida: {img_path}")
                    os.remove(img_path)

url = "https://download.microsoft.com/download/3/e/1/3e1c3f21-ecdb-4869-8368-6deba77b919f/kagglecatsanddogs_5340.zip"
zip_name = url.split('/')[-1] # Atritui apenas o nome do arquivo zip, a partir da url

extract_zip_file(url, zip_name) # Executa a função para extrair o arquivo zip
remove_corrupted_images('PetImages') # Executa a função para remover imagens corrompidas

"""Passo 3: Verificar a estrutura dos dados"""

if os.path.exists('PetImages'):
  print("Estrutura do dataset: ")
  for root, dirs, files in os.walk('PetImages'):
    print(f"{root}: {len(files)}")

"""Passo 4: Configuração dos parametros e pré-processamento"""

# CONSTANTES PARA OS PARAMETROS DAS FUNÇÕES DE TREINO E VALIDAÇÃO
IMG_SIZE = 160
BATCH_SIZE = 16
EPOCHS = 10
LEARNING_RATE = 0.0001

# FUNÇÃO DO TENSORFLOW QUE ESPECIFICA OS PARAMETROS DE TREINO E SUAS CLASSES
train_dataset = tf.keras.utils.image_dataset_from_directory(
    'PetImages', # Especifica o caminho da pasta raiz onde estão as classes Cat e Dog
    validation_split=0.2, # Determina que 20% das imagens serão usadas na validação ()
    subset='training', # Determinta que o conjunto será de treino
    seed=123, # Garante a divisão  treino/validação seja igual
    image_size=(IMG_SIZE, IMG_SIZE), # Redimenciona todas as imagens para o padrão da rede neural
    batch_size=BATCH_SIZE, # determina o tamanho do lote de imagens que serão passadas ao modelo por vez
)

# FUNÇÃO DO TENSORFLOW QUE ESPECIFICA OS PARAMETROS DE VALIDAÇÃO E SUAS CLASSES
val_dataset = tf.keras.utils.image_dataset_from_directory(
    'PetImages',
    validation_split=0.2,
    subset='validation',  # Determinta que o conjunto será de validação
    seed=123,
    image_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
)

# COMO OBTER O NOME DAS CLASSES
class_names = train_dataset.class_names
print(class_names)

# VISUALIZAR ALGUMAS IMAGENS
print("Visualizando algumas imagens do dataset:")
plt.figure(figsize=(5, 5))
for images, labels in train_dataset.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")

plt.tight_layout()
plt.show()

"""Passo 5: Otimização de performance e normalização"""

AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_dataset = val_dataset.cache().prefetch(buffer_size=AUTOTUNE)

"""Passo 6: Carregar o modelo Base MobileNetV2"""

# Carregar MobileNetV2 pré-treinado na imagenet
base_model = tf.keras.applications.MobileNetV2(input_shape=(IMG_SIZE, IMG_SIZE, 3),
                                               include_top=False, # não inclui a camada de classificação final
                                               weights='imagenet') # usar os pesos pre-treinados da ImageNet

# Congela as camadas do modelo base
base_model.trainable = False

print(f"modelo base carregado: {base_model.name}")
print(f"modelo base possui {len(base_model.layers)} camadas")

"""Passo 7: Construir o modelo completo"""

# Cria camadas de pré-processamento
preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input

# Criar o modelo completo
inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))

# Pré-Processamento para o MobileNetV2
x = preprocess_input(inputs)

# Modelo Base
x = base_model(x, training=False)

# Camadas de classificação personalizadas
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dropout(0.2)(x)
outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)

# Cria o modelo
model = tf.keras.Model(inputs, outputs)

# Compilação do Modelo
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Gera um resumo do modelo
model.summary()

"""Passo 8: Treinar o Modelo"""

train_dataset = train_dataset.apply(tf.data.experimental.ignore_errors())

val_dataset = val_dataset.apply(tf.data.experimental.ignore_errors())

# Treinar Modelo
history = model.fit(train_dataset,
                    epochs=EPOCHS,
                    validation_data=val_dataset,
                    verbose=1)

print("Treinamento concluído")

"""Análise da Curva de Aprendizado"""

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize=(8, 8))
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.ylabel('Accuracy')
plt.ylim([min(plt.ylim()),1])
plt.title('Training and Validation Accuracy')

plt.subplot(2, 1, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.ylabel('Cross Entropy')
plt.ylim([0,1.0])
plt.title('Training and Validation Loss')
plt.xlabel('epoch')
plt.show()